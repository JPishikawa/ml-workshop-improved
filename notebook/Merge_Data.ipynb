{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterHub Notebook\n",
    "\n",
    "### This notebook server is hosted on the OpenShift platform which provides a separate server for each individual user. The platform takes care of the provisioning of the server and allocating related to storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, install and import required libraries, watermark our file, initialise our Spark Session Builder and initialise our environment with required configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watermark\n",
      "  Downloading watermark-2.2.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: ipython in /opt/app-root/lib/python3.8/site-packages (from watermark) (7.28.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (3.0.20)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (58.1.0)\n",
      "Requirement already satisfied: pygments in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (0.17.2)\n",
      "Requirement already satisfied: backcall in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib/python3.8/site-packages (from ipython->watermark) (5.1.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/app-root/lib/python3.8/site-packages (from jedi>=0.16->ipython->watermark) (0.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/app-root/lib/python3.8/site-packages (from pexpect>4.3->ipython->watermark) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
      "Installing collected packages: watermark\n",
      "Successfully installed watermark-2.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Minio in /opt/app-root/lib/python3.8/site-packages (6.0.2)\n",
      "Requirement already satisfied: configparser in /opt/app-root/lib/python3.8/site-packages (from Minio) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/app-root/lib/python3.8/site-packages (from Minio) (2.8.2)\n",
      "Requirement already satisfied: urllib3 in /opt/app-root/lib/python3.8/site-packages (from Minio) (1.26.7)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib/python3.8/site-packages (from Minio) (2021.1)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib/python3.8/site-packages (from Minio) (2021.5.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.8/site-packages (from python-dateutil->Minio) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.2-py3-none-any.whl (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 134.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.8/site-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/app-root/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting setuptools-scm>=4\n",
      "  Downloading setuptools_scm-6.3.2-py3-none-any.whl (33 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████�^C███████▏     | 12.9 MB 125.3 MB/s eta 0:00:01\n",
      "\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install watermark\n",
    "%pip install Minio\n",
    "%pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_197/2473465872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import from_json, col, to_json, struct\n",
    "import watermark\n",
    "from minio import Minio\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%watermark -n -v -m -g -iv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sparkSessionBuilder = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Customer Churn ingest Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submit_args = \"--conf spark.jars.ivy=/tmp \\\n",
    "--conf spark.hadoop.fs.s3a.endpoint=http://minio-ml-workshop:9000 \\\n",
    "--conf spark.hadoop.fs.s3a.access.key=minio \\\n",
    "--conf spark.hadoop.fs.s3a.secret.key=minio123 \\\n",
    "--conf spark.hadoop.fs.s3a.path.style.access=true \\\n",
    "--conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \\\n",
    "--packages org.apache.hadoop:hadoop-aws:3.2.0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Connect to Spark Cluster provided by OpenShift Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spark_util\n",
    "\n",
    "spark = spark_util.getOrCreateSparkSession(\"ML Ops Demo\", submit_args)\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "print('Spark context started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Declare our input data sources, import and combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataFrame_Customer = spark.read\\\n",
    "                .options(delimeter=',', inferSchema='True', header='True') \\\n",
    "                .csv(\"s3a://rawdata/customers/Customer-Churn_P1.csv\")\n",
    "dataFrame_Customer.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataFrame_Products = spark.read\\\n",
    "                .options(delimeter=',', inferSchema='True', header='True') \\\n",
    "                .csv(\"s3a://rawdata/products/Customer-Churn_P2.csv\")\n",
    "dataFrame_Products.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import *\n",
    "# from  pyspark.sql.functions import *\n",
    "\n",
    "# srcKafkaBrokers = \"odh-message-bus-kafka-bootstrap:9092\"\n",
    "# srcKakaTopic = \"datatelco\"\n",
    "\n",
    "\n",
    "\n",
    "# schema = StructType()\\\n",
    "#     .add(\"customerID\", IntegerType())\\\n",
    "#     .add(\"PhoneService\", StringType())\\\n",
    "#     .add(\"MultipleLines\", StringType())\\\n",
    "#     .add(\"InternetService\", StringType())\\\n",
    "#     .add(\"OnlineSecurity\", StringType())\\\n",
    "#     .add(\"OnlineBackup\", StringType())\\\n",
    "#     .add(\"DeviceProtection\", StringType())\\\n",
    "#     .add(\"TechSupport\", StringType())\\\n",
    "#     .add(\"StreamingTV\", StringType())\\\n",
    "#     .add(\"StreamingMovies\", StringType())\\\n",
    "#     .add(\"Contract\", StringType())\\\n",
    "#     .add(\"PaperlessBilling\", StringType())\\\n",
    "#     .add(\"PaymentMethod\", StringType())\\\n",
    "#     .add(\"MonthlyCharges\", StringType())\\\n",
    "#     .add(\"TotalCharges\", DoubleType())\\\n",
    "#     .add(\"Churn\", StringType())\n",
    "\n",
    "\n",
    "\n",
    "# #Read from JSON Kafka messages into a dataframe\n",
    "# dfKafka = spark.read.format(\"kafka\")\\\n",
    "#     .option(\"kafka.bootstrap.servers\", srcKafkaBrokers)\\\n",
    "#     .option(\"subscribe\", srcKakaTopic)\\\n",
    "#     .option(\"startingOffsets\", \"earliest\")\\\n",
    "#     .load()\\\n",
    "#     .withColumn(\"value\", regexp_replace(col(\"value\").cast(\"string\"), \"\\\\\\\\\", \"\")) \\\n",
    "#     .withColumn(\"value\", regexp_replace(col(\"value\"), \"^\\\"|\\\"$\", \"\")) \\\n",
    "#     .selectExpr(\"CAST(value AS STRING) as jsonValue\")\\\n",
    "#     .rdd.map(lambda row: row[\"jsonValue\"])\n",
    "\n",
    "# dfObj = spark.read.schema(schema).json(dfKafka)\n",
    "# dfObj.printSchema()\n",
    "# dfObj.show(n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataFrom_All = dataFrame_Customer.join(dataFrame_Products, \"customerID\", how=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Push prepared data to object storage and stop Spark cluster to save resources\n",
    "###  Note - be sure to change this user_id on the next line to your username (something in the range user1 ... user30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_id = \"user29\"\n",
    "file_location = \"s3a://data/full_data_csv\" + user_id\n",
    "dataFrom_All.repartition(1).write.mode(\"overwrite\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .format(\"csv\").save(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "545e036c4b32438aced1f6b3c8d38ca151d9c36189e05839cb0aa568fda70ddd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
